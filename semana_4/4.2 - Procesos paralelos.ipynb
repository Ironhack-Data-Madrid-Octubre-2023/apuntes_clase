{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 - Procesos paralelos\n",
    "\n",
    "\n",
    "![parallel](images/parallel.png)\n",
    "\n",
    "$$$$\n",
    "\n",
    "### Multiprocessing\n",
    "\n",
    "Veamos en primer lugar [multiprocessing](https://docs.python.org/es/3.9/library/multiprocessing.html). Es una librería de Python que nos permite manejar hilos y procesos. La diferencia entre hilo y proceso es que un hilo ocurre dentro del espacio de memoria de un programa y un proceso es una copia completa del programa, por esta razón, los hilos son rápidos de crear y destruir además de que consumen poca memoria y los procesos son lentos de crear y destruir además de que requieren clonar el espacio de memoria del programa en otro lugar de la RAM, y esto es lento. Ejemplos de esto serían, subrutinas que recogen mensajes de un puerto de comunicaciones y los usan para actuar sobre emails almacenados en un servidor, desde el punto de vista del servidor, el cliente de correo sólo necesita usar el servidor durante un corto plazo de tiempo, porque envía un mensaje al servidor donde le indica lo que el usuario desea hacer, saber si hay mensajes nuevos, borrar un correo, moverlo... El servidor abre un hilo para atender a ese usuario y el hilo sólo vive mientras dure la conexión del usuario, una vez el usuario ha terminado el cliente de correo desconecta hasta nueva acción. Este proceso que he descrito es rápido, ocurre en milisegundos y generalmente se resuelve con hilos porque es más ligero para el sistema operativo y su vida media es especialmente corta, además de que el sistema podrá aceptar ciento o miles de conexiones por segundo y será ligero, rápido y eficiente en esta tarea.\n",
    "\n",
    "La tendencia actual entre los desarrolladores es hacer una aplicaciones que sean rápidas en un sólo hilo y luego escalar a tantas instancias como sea necesario para cubrir nuestros objetivos de aprovechamiento, estos servidores pueden atender en un sólo proceso a miles o decena de miles de conexiones.\n",
    "\n",
    "Si queremos realizar un programa que aproveche las diferentes CPUs y pueda realizar múltiples tareas a la vez tenemos muchos mecanismos para llevar esta tarea a cabo. Dependiendo del uso que se quiera dar probablemente queramos usar hilos o procesos, es aquí donde querremos escribir nuestro código con hilos o procesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hola Mundo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuadrado(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [i for i in range(10_000_000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seq = [cuadrado(x) for x in data]\n",
    "\n",
    "seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "map(cuadrado, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seq=list(map(cuadrado, data))\n",
    "\n",
    "seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movida del Mac M1\n",
    "\n",
    "mp.get_start_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movida del mac M1, para otros no hace falta\n",
    "\n",
    "from multiprocessing import get_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.cpu_count()    # nº de nucleos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#pool = mp.Pool(mp.cpu_count())    # usar todos los nucleos (Intel o AMD)\n",
    "\n",
    "pool = get_context('fork').Pool(mp.cpu_count())  # ARM M1  (en vez de ir de 1en1 va de 8en8)\n",
    " \n",
    "seq = pool.map(cuadrado, data)\n",
    "\n",
    "pool.close()\n",
    "\n",
    "seq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multiprocessing asíncrono**\n",
    "\n",
    "`map` consume su iterable convirtiendo el iterable en una lista, dividiéndolo en fragmentos y enviando esos fragmentos a los procesos de trabajo en el Pool. Dividir el iterable en fragmentos funciona mejor que pasar cada elemento en el iterable entre procesos un elemento a la vez, especialmente si el iterable es grande. Sin embargo, convertir el iterable en una lista para dividirlo puede tener un costo de memoria muy alto, ya que la lista completa deberá mantenerse en la memoria.\n",
    "\n",
    "`imap`/`map_async` no convierte el iterable que le da en una lista, ni lo divide en trozos. Itera sobre el elemento de uno en uno y los envia a un proceso de trabajo distinto. Esto significa que no se toma el golpe de memoria de convertir todo el iterable en una lista, pero también que el rendimiento es más lento para los iterables grandes, debido a la falta de fragmentación. Esto se puede mitigar aumentando el valor predeterminado de 1 en el `chunksize`. Otra gran diferencia de `imap` es que puede comenzar a recibir resultados de los trabajadores tan pronto como estén listos, en lugar de tener que esperar a que todos terminen. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#pool=mp.Pool(mp.cpu_count())\n",
    "\n",
    "pool=get_context('fork').Pool(6)  # grupo con 6 cores\n",
    "\n",
    "res=pool.map_async(cuadrado, data).get()\n",
    "\n",
    "pool.close()\n",
    "\n",
    "res[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%time\n",
    "pool=mp.Pool(mp.cpu_count())   \n",
    "\n",
    "for x in pool.imap(cuadrado, datos):\n",
    "    print(x)\n",
    "    \n",
    "pool.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$$$\n",
    "\n",
    "$$$$\n",
    "\n",
    "## Joblib\n",
    "\n",
    "![joblib](images/joblib.svg)\n",
    "\n",
    "$$$$\n",
    "\n",
    "$$$$\n",
    "\n",
    "\n",
    "[Joblib](https://joblib.readthedocs.io/en/latest/) es una librería de Python que también nos permite paralelizar un programa. En este caso a través de procesos, lo cuál implica, como vimos antes, cierto tiempo para construir el Pool. Lo usaremos principalmente para realizar un bucle sobre una función.\n",
    "\n",
    "Veamos el Hola Mundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hola Mundo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "paralelo = Parallel(n_jobs=-1,   # n_jobs es el nº de nuncleos que usas, -1 = todos\n",
    "                    verbose=True\n",
    "                   )\n",
    "\n",
    "\n",
    "seq = paralelo(delayed(cuadrado)(e) for e in data)\n",
    "\n",
    "seq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo ESPN\n",
    "\n",
    "Volvamos de nuevo al ejemplo de scrapeo de la págine de ESPN. Usaremos joblib para realizar una extracción en paralelo de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PATH='driver/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.espn.com/soccer/competitions'\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "aceptar=driver.find_element(By.XPATH, '//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "aceptar.click()\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "equipos=driver.find_element(By.CSS_SELECTOR, '#fittPageContainer > div.page-container.cf > div > div.layout__column.layout__column--1 > div > div:nth-child(3) > div:nth-child(1) > div > div:nth-child(5) > div > section > div > div > span:nth-child(2) > a')\n",
    "equipos.click()\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "equipos_stats_urls=driver.find_elements(By.CSS_SELECTOR, 'a.AnchorLink')\n",
    "\n",
    "equipos_stats_urls=[e.get_attribute('href') for e in equipos_stats_urls \n",
    "                    if 'team/stats' in e.get_attribute('href')]\n",
    "\n",
    "\n",
    "equipos_stats_urls[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRORES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer(url):\n",
    "\n",
    "    # inicia el driver\n",
    "    driver=webdriver.Chrome(PATH)\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    # acepta cookies\n",
    "    aceptar=driver.find_element(By.XPATH, '//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "    aceptar.click()\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    data=[]\n",
    "    cabeceras=[]\n",
    "    \n",
    "    try:\n",
    "        # dropdown\n",
    "        dropdown = driver.find_element(By.XPATH, '//*[@id=\"fittPageContainer\"]/div[2]/div[5]/div/div/section/div/div[4]/select[1]')\n",
    "        select = Select(dropdown)\n",
    "        try:\n",
    "            select.select_by_visible_text('2022-23')\n",
    "        except:\n",
    "            select.select_by_visible_text('2023-24')\n",
    "\n",
    "\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        # disciplina\n",
    "        dis=driver.find_element(By.XPATH, '//*[@id=\"fittPageContainer\"]/div[2]/div[5]/div/div[1]/section/div/div[2]/nav/ul/li[2]/a')\n",
    "        dis.click()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        tabla=driver.find_element(By.TAG_NAME, 'tbody')\n",
    "\n",
    "        filas=tabla.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "        for f in filas:\n",
    "\n",
    "            elementos=f.find_elements(By.TAG_NAME, 'td') \n",
    "\n",
    "            tmp=[]\n",
    "\n",
    "            for e in elementos:\n",
    "\n",
    "                tmp.append(e.text)\n",
    "\n",
    "            tmp.append(url.split('/')[-1])  # nombre del equipo\n",
    "            data.append(tmp)\n",
    "\n",
    "\n",
    "        cabeceras=driver.find_element(By.TAG_NAME, 'thead')\n",
    "\n",
    "        cabeceras=[c.text for c in cabeceras.find_elements(By.TAG_NAME, 'th')]+['TEAM']\n",
    "\n",
    "    except:\n",
    "        ERRORES.append(url.split('/')[-1])\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    driver.quit()\n",
    "    \n",
    "    return pd.DataFrame(data, columns=cabeceras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paralelo = Parallel(n_jobs=6, verbose=True)\n",
    "\n",
    "\n",
    "lst_df = paralelo(delayed(extraer)(url) for url in equipos_stats_urls[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df = lst_df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(lst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TEAM.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.TEAM.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** https://pypi.org/project/tqdm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para barras de progreso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paralelo = Parallel(n_jobs=6, verbose=False)\n",
    "\n",
    "\n",
    "lst_df = paralelo(delayed(extraer)(url) for url in tqdm(equipos_stats_urls[:10]))\n",
    "\n",
    "\n",
    "df = pd.concat(lst_df)\n",
    "\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.TEAM.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clase",
   "language": "python",
   "name": "clase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
